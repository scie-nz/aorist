type: Constraint
spec:
  name: DownloadDataFromRemotePushshiftAPILocationToNewlineDelimitedJSON
  root: PushshiftAPILocation
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
  title: Downloading data from the Pushshift API
  body: |
      Data for this particular asset(s) is located in the Pushshift API.
      We need to download it to a local directory first, before we can
      do anything with it.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
      match ancestry.replication_storage_setup(root.clone()) {
          Ok(x) => {
            debug!("Root has ReplicationStorageSetup.");
            match *x.0.read().tmp_encoding.0.read() {
                scienz::Encoding::NewlineDelimitedJSONEncoding(_) => true,
                scienz::Encoding::CSVEncoding(_) => true,
                _ => false,
            }
          }
          _ => false,
      }
---
type: Constraint
spec:
  name: HiveDirectoriesCreated
  root: HiveLocation
  requiresProgram: true
  title: Created hive directories.
  body: |
      We need to create directories or buckets (depending on file system / storage
      solution) in which we will store our Hive data.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
          ancestry.hive_table_storage(root.clone()).is_ok() &&
          ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: ConvertJSONToCSV
  root: RemoteStorage
  requiresProgram: true
  requires:
    - DownloadDataFromRemotePushshiftAPILocationToNewlineDelimitedJSON
  title: Convert JSON data to CSV
  body: |
      We need to convert the JSON data to CSV format to process it further.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          match *ancestry.remote_storage(root.clone()).unwrap().0.read().encoding.0.read() {
              scienz::Encoding::NewlineDelimitedJSONEncoding(_) => {
                  ancestry.replication_storage_setup(root.clone()).is_ok()
              },
              _ => false,
          }
      }
---
type: Constraint
spec:
  name: ReadyForUpload
  root: StaticDataTable
  requires:
    - DownloadDataFromRemotePushshiftAPILocationToNewlineDelimitedJSON
    - DownloadDataFromRemoteGCSLocation
  title: Data has now been downloaded
---
type: Constraint
spec:
  name: UploadDataToMinio
  root: MinioLocation
  requiresProgram: true
  requires:
    - ReadyForUpload
    - HiveDirectoriesCreated
  title: Upload data to Min.IO
  body: |
      Now that data has been pre-processed we can upload it to the underlying
      Min.IO storage.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
        ancestry.replication_storage_setup(root.clone()).is_ok()
      }
---
type: Constraint
spec:
  name: UploadDataToSQLite
  root: SQLiteLocation
  requires:
    - ReadyForUpload
  requiresProgram: true
  title: Upload data to SQLite
  body: |
      Now that data has been converted to a CSV we can upload it to SQLite.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: JSONTableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
  title: Create schemas for temporary JSON tables.
  body: |
      We will use Hive tables with external storage as a staging location for our
      data. We need to create these schemas to be able to write data to them.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
         match &*ancestry.hive_table_storage(root.clone()).unwrap().0.read().encoding.0.read() {
            scienz::Encoding::NewlineDelimitedJSONEncoding(_) => true,
            _ => false,
         }
      }
---
type: Constraint
spec:
  name: DownloadDataFromRemoteWebLocation
  root: WebLocation
  requiresProgram: true
  title: Downloading data from remote web location
  body: |
      Data for this particular asset(s) is located somewhere on the web.
      We need to download it to a local directory first, before we can
      do anything with it.
---
type: Constraint
spec:
  name: ConvertJSONTableToORCTable
  root: HiveTableStorage
  requires:
    - JSONTableSchemasCreated
    - ReplicateToLocal
    - ORCTableSchemasCreated
  requiresProgram: true
  title: Convert JSON Table to ORC Table
  body: |
      Hive tables can be stored in external JSON format, but this is inefficient.
      We can convert them to ORC (the native Hive format) to speed up access.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
      match ancestry.static_data_table(root.clone()) {
          Ok(sdt) => match &*sdt.0.read().setup.0.read() {
              scienz::StorageSetup::ReplicationStorageSetup(_) => true,
              _ => false,
          },
          _ => false,
      }
---
type: Constraint
spec:
  name: ReplicateToLocal
  root: OnPremiseLocation
  requires:
      - UploadDataToMinio
      - UploadDataToSQLite
---
type: Constraint
spec:
  name: ORCTableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  title: Creating Table Schemas
  body: |
      We will be uploading tabular data into our warehouse. Before we upload
      data files we need to create schemas for the tables which will refer
      to these files.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: TextCorpusData
  root: TextCorpus
  requires:
      - TextCorpusDataFromHive
      - TextCorpusDataFromSQLite
  title: Downloading TextCorpusData
---
type: Constraint
spec:
  name: TextCorpusDataFromHive
  root: TextCorpus
  requires:
      - ConvertJSONTableToORCTable
  requiresProgram: true
  title: Creating corpus-based dataset
  body: |
      We download text corpus data data from a Hive table.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          let language_asset = ancestry.language_asset(root.clone()).unwrap();
          for asset in language_asset.0.read().get_source_assets() {
              let storage_setup = scienz::TAsset::get_storage_setup(&asset);
              let local_storages = storage_setup.0.read().get_local_storage();
              let mut hive_storage = false;
              for storage in local_storages.iter() {
                  if let scienz::Storage::HiveTableStorage(_) = *storage.0.read() {
                      hive_storage = true;
                  }
              }
              if !hive_storage {
                  return false;
              }
          }
          return true;
      }
---
type: Constraint
spec:
  name: TextCorpusDataFromSQLite
  root: TextCorpus
  requires:
      - ReplicatedAsset
  requiresProgram: true
  title: Creating corpus-based dataset
  body: |
      We download corpus data from a SQLite table.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          let language_asset = ancestry.language_asset(root.clone()).unwrap();
          for asset in language_asset.0.read().get_source_assets() {
              let storage_setup = scienz::TAsset::get_storage_setup(&asset);
              let local_storages = storage_setup.0.read().get_local_storage();
              let mut sqlite_storage = false;
              for storage in local_storages.iter() {
                  if let scienz::Storage::SQLiteStorage(_) = *storage.0.read() {
                      sqlite_storage = true;
                  }
              }
              if !sqlite_storage {
                  return false;
              }
          }
          return true;
      }
  requiredConstraintsClosure: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          let language_asset = ancestry.language_asset(root.clone()).unwrap();
          let uuids = language_asset.0.read().get_source_assets()
              .iter().map(|x| x.get_uuid().unwrap()).collect::<Vec<_>>();
          uuids
      }
---
type: Constraint
spec:
  name: TrainFasttextModel
  root: FasttextEmbeddingSchema
  requires:
      - TextCorpusData
  requiresProgram: true
  title: Training Fasttext Model
  body: |
      This operation trains the Fasttext model and saves
      a dataset mapping words to their embeddings to a local
      file.
  requiredConstraintsClosure: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          vec![
              ancestry.fasttext_embedding_schema(root.clone()).unwrap().0.read().source.0.read().get_uuid().clone().unwrap()
          ]
      }
---
type: Constraint
spec:
  name: UploadFasttextToMinio
  root: FasttextEmbeddingSchema
  requiresProgram: true
  requires:
      - TrainFasttextModel
  title: Upload data to Min.IO
  body: |
      Now that data has been pre-processed we can upload it to the underlying
      Min.IO storage.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          match ancestry.fasttext_embedding(root.clone()) {
              Ok(x) => match *x.0.read().setup.0.read() {
                  scienz::StorageSetup::LocalStorageSetup(ref s) => match *s.0.read().local.0.read() {
                      scienz::Storage::HiveTableStorage(ref h) => match *h.0.read().location.0.read() {
                          scienz::HiveLocation::MinioLocation(_) => true,
                          _ => false,
                      },
                      _ => false,
                  },
                  _ => false,
              }
              Err(_) => false,
          }
      }
---
type: Constraint
spec:
  name: UploadFasttextToSQLite
  root: FasttextEmbeddingSchema
  requiresProgram: true
  requires:
      - TrainFasttextModel
  title: Upload Fasttext word vectors to SQLite
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          match ancestry.fasttext_embedding(root.clone()) {
              Ok(x) => match *x.0.read().setup.0.read() {
                  scienz::StorageSetup::LocalStorageSetup(ref s) => match *s.0.read().local.0.read() {
                      scienz::Storage::SQLiteStorage(_) => true,
                      _ => false,
                  },
                  _ => false,
              }
              Err(_) => false,
          }
      }
---
type: Constraint
spec:
  name: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  requiresProgram: true
  title: Downloading data from GCS
  body: |
      Data for this particular asset(s) is located in Google Cloud Storage.
      We need to download it to a local directory first, before we can
      do anything with it.
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
      match ancestry.replication_storage_setup(root.clone()) {
          Ok(_) => true, 
          /*{
            debug!("Root has ReplicationStorageSetup.");
            match *x.0.read().tmp_encoding.0.read() {
                scienz::Encoding::NewlineDelimitedJSONEncoding(_) => true,
                scienz::Encoding::CSVEncoding(_) => true,
                _ => false,
            }
          }*/
          _ => false,
      }
---
type: Constraint
spec:
  name: DownloadDataFromRemote
  root: RemoteStorage
  requires:
    - DownloadDataFromRemoteGCSLocation
    - DownloadDataFromRemotePushshiftAPILocationToNewlineDelimitedJSON
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry|
      match ancestry.replication_storage_setup(root.clone()) {
          Ok(x) => {
            debug!("Root has ReplicationStorageSetup.");
            match *x.0.read().tmp_encoding.0.read() {
                scienz::Encoding::NewlineDelimitedJSONEncoding(_) => true,
                scienz::Encoding::CSVEncoding(_) => true,
                _ => false,
            }
          }
          _ => false,
      }
---
type: Constraint
spec:
  name: ExtractNamedEntitiesUsingSpaCy
  root: SpaCyNamedEntitySchema
  requires:
      - TextCorpusData
  requiresProgram: true
  title: Extracting named entities using SpaCy
  requiredConstraintsClosure: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          vec![
              ancestry.spa_cy_named_entity_schema(root.clone()).unwrap().0.read().source.0.read().get_uuid().clone().unwrap()
          ]
      }
---
type: Constraint
spec:
  name: ReplicatedAsset
  root: Asset
  requires:
    - UploadDataToMinio
    - UploadDataToSQLite
---
type: Constraint
spec:
  name: UploadSpaCyToSQLite
  root: SpaCyNamedEntitySchema
  requiresProgram: true
  requires:
      - ExtractNamedEntitiesUsingSpaCy
  title: Upload SpaCy named entities to SQLite
  attachIf: |
      |root: AoristRef<Concept>, ancestry: &ConceptAncestry| {
          match ancestry.named_entities(root.clone()) {
              Ok(x) => match *x.0.read().setup.0.read() {
                  scienz::StorageSetup::LocalStorageSetup(ref s) => match *s.0.read().local.0.read() {
                      scienz::Storage::SQLiteStorage(_) => true,
                      _ => false,
                  },
                  _ => false,
              }
              Err(_) => false,
          }
      }
